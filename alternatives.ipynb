{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33c962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchmetrics #when using google colab extension enable this line\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ae8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28af451",
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec0f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "396ce1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5000, 1: 4630}\n",
      "{0: 5000, 1: 4630}\n",
      "{0: 5000, 1: 4630}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), # Resize all images to a uniform size (e.g., 64x64 pixels)\n",
    "    transforms.ToTensor(), # Convert PIL Image to PyTorch tensor (0-255 to 0.0-1.0)\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize pixel values\n",
    "])\n",
    "\n",
    "train_data_dir = 'dataset/Human Faces Dataset' \n",
    "full_dataset = torchvision.datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [0.7, 0.3])\n",
    "\n",
    "\n",
    "print(dict(Counter(train_dataset.dataset.targets)))\n",
    "\n",
    "print(dict(Counter(test_dataset.dataset.targets)))\n",
    "print(dict(Counter(full_dataset.targets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c04392",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m train_loader = DataLoader(\n\u001b[32m      3\u001b[39m     train_dataset,\n\u001b[32m      4\u001b[39m     batch_size=batch_size,\n\u001b[32m      5\u001b[39m     shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Shuffle data for training\u001b[39;00m\n\u001b[32m      6\u001b[39m     num_workers=\u001b[32m2\u001b[39m \u001b[38;5;66;03m# Use multiple subprocesses for data loading \u001b[39;00m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# get some random training images\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m dataiter = \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m images, labels = \u001b[38;5;28mnext\u001b[39m(dataiter)\n\u001b[32m     13\u001b[39m imshow(torchvision.utils.make_grid(images))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1170\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1163\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1164\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\context.py:337\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\popen_spawn_win32.py:97\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     96\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     99\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mount\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, # Shuffle data for training\n",
    "    num_workers=2 # Use multiple subprocesses for data loading \n",
    ")\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b524cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the targets for the subset\n",
    "subset_targets = [full_dataset.targets[i] for i in test_dataset.indices]\n",
    "\n",
    "# Calculate the class distribution\n",
    "class_distribution = Counter(subset_targets)\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, # Shuffle data for training\n",
    "    num_workers=2 # Use multiple subprocesses for data loading \n",
    ")\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d29e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check (set shuffle=False in loader so order in file explorer is perserved)\n",
    "index=0\n",
    "npimg=train_loader.dataset[index][0].numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()\n",
    "train_loader.dataset[index][1]\n",
    "\n",
    "img, label=train_loader.dataset[index]\n",
    "img.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7c7bd",
   "metadata": {},
   "source": [
    "<h2> FEATURE EXTRACTION FUNCTION </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to extract features \n",
    "def extract_features(data_loader):\n",
    "    #iterates through DataLoader and flattens image tensors\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in data_loader:\n",
    "        # flatten the image data: C * H * W\n",
    "        # resulting shape: (Batch, Features)\n",
    "        flattened_images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "        # convert to numpy and append\n",
    "        all_features.append(flattened_images.numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "    # concatenates all batches into single numpy arrays\n",
    "    X = np.concatenate(all_features, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19ace1",
   "metadata": {},
   "source": [
    "<h2> LP </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b505a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_loader = DataLoader(full_dataset, batch_size=64, shuffle=False)\n",
    "print(\"Processing all image data...\")\n",
    "X_full, y_true_full = extract_features(full_loader)\n",
    "print(f\"Feature Matrix Shape (X_full): {X_full.shape}\")\n",
    "\n",
    "train_indices = train_dataset.indices\n",
    "all_indices = np.arange(len(full_dataset))\n",
    "\n",
    "\n",
    "y_lp = np.full(len(full_dataset), -1)\n",
    "y_lp[train_indices] = y_true_full[train_indices] # now y_lp has true labels (0-9) for training set samples, -1 for test set samples\n",
    "# X_full contains the features for ALL samples\n",
    "# y_lp contains labels for labeled samples and -1 for unlabeled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "\n",
    "print(\"\\nStarting Label Propagation...\")\n",
    "label_propagator = LabelPropagation(kernel='knn', n_neighbors=7)\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "'kernel': ['knn', 'rbf'],  \n",
    "'n_neighbors': [3, 5, 7, 10, 15, 20],\n",
    "'gamma': np.linspace(0.1, 5.0, 30).tolist()\n",
    "}\n",
    "\n",
    "label_propagator.fit(X_full, y_lp)\n",
    "print(\"Label Propagation complete.\")\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(label_propagator, param_dist, n_iter=50,cv=5,return_train_score=True, verbose=5)\n",
    "random_search.fit(X_full, y_lp)\n",
    "\n",
    "print(\"Best parameters (RandomizedSearchCV):\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb188623",
   "metadata": {},
   "source": [
    "<!-- <h2> GB </h2> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ae7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Training Data...\")\n",
    "X_train, y_train = extract_features(train_loader)\n",
    "\n",
    "print(\"Processing Testing Data...\")\n",
    "X_test, y_test = extract_features(test_loader)\n",
    "\n",
    "print(f\"\\nFinal X_train shape for GB: {X_train.shape}\")\n",
    "print(f\"Final X_test shape for GB: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501109e",
   "metadata": {},
   "source": [
    "<h1> GRADIENT BOOSTING </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e2ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gb.fit(X_train,y_train)\n",
    "\n",
    "y_predictions=gb.predict(X_test)\n",
    "\n",
    "print(\"GRADIENT BOOSTING\")\n",
    "print(classification_report(y_test,y_predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gb_disp = RocCurveDisplay.from_estimator(gb, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "'max_depth' : [5, 50, 500],\n",
    "'max_features': [10, 100, 1000]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(gb, param_dist,  n_iter=10, cv=5, return_train_score=True, verbose=5)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters (RandomizedSearchCV):\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd014126",
   "metadata": {},
   "source": [
    "<h1> SINGLE DECISION TREE </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train,y_train)\n",
    "\n",
    "y_predictions=dt.predict(X_test)\n",
    "\n",
    "print(\"SINGLE DECISION TREE\")\n",
    "print(classification_report(y_test,y_predictions))\n",
    "\n",
    "tree.plot_tree(dt)\n",
    "\n",
    "dt_disp = RocCurveDisplay.from_estimator(dt, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "'splitter': ['best', 'random'],\n",
    "'max_depth' : [5, 50, 500],\n",
    "'max_features': ['None', 'log2', 'sqrt']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(dt, param_dist,  n_iter=10, cv=5, return_train_score=True, verbose=5)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters (RandomizedSearchCV):\", random_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
